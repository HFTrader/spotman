#!/usr/bin/env python3
"""
SpotMan - AWS EC2 Instance Manager
A comprehensive tool for managing AWS EC2 instances with application class tagging.
"""

import argparse
import json
import os
import sys
import time
import yaml
from typing import Dict, List, Optional, Any
import boto3
from botocore.exceptions import ClientError, NoCredentialsError
import subprocess
import base64


class IncludeLoader(yaml.SafeLoader):
    """Custom YAML loader that supports !include directives."""
    
    def __init__(self, stream):
        # Set root to the parent directory of the profile (SpotMan directory)
        self._root = os.path.dirname(os.path.dirname(stream.name))
        super().__init__(stream)

    def include(self, node):
        """Include file referenced in !include directive."""
        filename = self.construct_scalar(node)
        
        # Handle relative paths relative to SpotMan root directory
        if not os.path.isabs(filename):
            filename = os.path.join(self._root, filename)
        
        try:
            with open(filename, 'r') as f:
                content = f.read()
                print(f"Loaded external script: {os.path.relpath(filename, self._root)}")
                return content
        except FileNotFoundError:
            print(f"Error: Include file '{filename}' not found")
            # List available scripts to help the user
            scripts_dir = os.path.join(self._root, 'scripts')
            if os.path.exists(scripts_dir):
                available_scripts = [f for f in os.listdir(scripts_dir) if f.endswith('.sh')]
                if available_scripts:
                    print(f"Available scripts in scripts/: {', '.join(available_scripts)}")
            sys.exit(1)
        except Exception as e:
            print(f"Error reading include file '{filename}': {e}")
            sys.exit(1)


# Add the include constructor to the custom loader
IncludeLoader.add_constructor('!include', IncludeLoader.include)


class AWSInstanceManager:
    """Manages AWS EC2 instances with application class tagging."""
    
    def __init__(self, region: str = None, profile: str = None):
        """Initialize the AWS session and EC2 client."""
        try:
            # Track if region was explicitly provided
            self.region_explicit = region is not None
            
            # Get region: command line > last used > AWS session default
            self.region = region or self._get_last_used_region()
            
            session = boto3.Session(profile_name=profile, region_name=self.region)
            self.ec2_client = session.client('ec2')
            self.ec2_resource = session.resource('ec2')
            
            # If no region was explicitly provided, use session default
            if not self.region:
                self.region = session.region_name
            
            # Save the region as last used when explicitly provided via --region
            if self.region_explicit:
                self._save_last_used_region(self.region)
            # Also save as last used if no explicit region but we got one from session/default
            elif not self.region_explicit and self.region:
                self._save_last_used_region(self.region)
            
            # Load region configuration
            self.regions_config = self._load_regions_config()
        except NoCredentialsError:
            print("Error: AWS credentials not found. Please configure your credentials.")
            sys.exit(1)
        except Exception as e:
            print(f"Error initializing AWS session: {e}")
            sys.exit(1)

    def load_profile(self, profile_name: str) -> Dict[str, Any]:
        """Load instance profile from YAML file with native !include support."""
        # Construct the full path to the profile file
        script_dir = os.path.dirname(os.path.abspath(__file__))
        profile_path = os.path.join(script_dir, 'profiles', f'{profile_name}.yaml')
        
        try:
            with open(profile_path, 'r') as f:
                profile = yaml.load(f, Loader=IncludeLoader)
            
            return profile
        except FileNotFoundError:
            print(f"Error: Profile '{profile_name}' not found at '{profile_path}'.")
            # List available profiles to help the user
            profiles_dir = os.path.join(script_dir, 'profiles')
            if os.path.exists(profiles_dir):
                available_profiles = [f[:-5] for f in os.listdir(profiles_dir) if f.endswith('.yaml')]
                if available_profiles:
                    print(f"Available profiles: {', '.join(available_profiles)}")
            sys.exit(1)
        except yaml.YAMLError as e:
            print(f"Error parsing YAML profile: {e}")
            sys.exit(1)

    def _load_regions_config(self) -> Dict[str, Any]:
        """Load region configuration from regions.yaml file."""
        # Look for regions.yaml in the same directory as the script
        script_dir = os.path.dirname(os.path.abspath(__file__))
        regions_file = os.path.join(script_dir, 'regions.yaml')
        
        try:
            with open(regions_file, 'r') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            print(f"Warning: Regions configuration file '{regions_file}' not found.")
            print("Using legacy profile format or create regions.yaml for region-agnostic profiles.")
            return {}
        except yaml.YAMLError as e:
            print(f"Error parsing regions configuration: {e}")
            sys.exit(1)

    def _get_config_dir(self) -> str:
        """Get the SpotMan configuration directory."""
        config_dir = os.path.expanduser('~/.spotman')
        if not os.path.exists(config_dir):
            os.makedirs(config_dir)
        return config_dir

    def _get_last_used_region(self) -> Optional[str]:
        """Get the last used region from configuration."""
        config_file = os.path.join(self._get_config_dir(), 'config.yaml')
        try:
            with open(config_file, 'r') as f:
                config = yaml.safe_load(f)
                last_region = config.get('last_used_region')
                if last_region:
                    print(f"Using last used region: {last_region}")
                return last_region
        except (FileNotFoundError, yaml.YAMLError):
            return None

    def _save_last_used_region(self, region: str) -> None:
        """Save the last used region to configuration."""
        config_dir = self._get_config_dir()
        config_file = os.path.join(config_dir, 'config.yaml')
        
        # Load existing config or create new
        config = {}
        try:
            with open(config_file, 'r') as f:
                config = yaml.safe_load(f) or {}
        except (FileNotFoundError, yaml.YAMLError):
            pass
        
        # Update last used region
        config['last_used_region'] = region
        
        # Save config
        try:
            with open(config_file, 'w') as f:
                yaml.dump(config, f, default_flow_style=False)
        except Exception as e:
            # Don't fail if we can't save config, just warn
            print(f"Warning: Could not save last used region: {e}")

    def get_current_region(self) -> str:
        """Get the current region being used."""
        return self.region

    def set_default_region(self, region: str) -> bool:
        """Set the default region for future operations."""
        # Validate that the region exists in our configuration
        if self.regions_config and 'regions' in self.regions_config:
            if region not in self.regions_config['regions']:
                available_regions = list(self.regions_config['regions'].keys())
                print(f"Error: Region '{region}' not configured.")
                print(f"Available regions: {available_regions}")
                return False
        
        self._save_last_used_region(region)
        print(f"Default region set to: {region}")
        return True

    def hibernate_instance(self, instance_identifier: str) -> bool:
        """Hibernate an EC2 instance by ID or name."""
        # Resolve instance name to ID if needed
        instance_id = self._resolve_instance_identifier(instance_identifier)
        if not instance_id:
            return False
        
        try:
            # Check if hibernation is configured and instance is running
            response = self.ec2_client.describe_instances(InstanceIds=[instance_id])
            instance = response['Reservations'][0]['Instances'][0]
            current_state = instance['State']['Name']
            hibernation_configured = instance.get('HibernationOptions', {}).get('Configured', False)
            
            if current_state != 'running':
                print(f"Instance {instance_id} is in '{current_state}' state. Can only hibernate running instances.")
                return False
                
            if not hibernation_configured:
                print(f"Warning: Instance {instance_id} was not configured for hibernation at launch.")
                print("Proceeding with regular stop instead of hibernation...")
                self.ec2_client.stop_instances(InstanceIds=[instance_id])
            else:
                print(f"Hibernating instance {instance_id}...")
                print("💾 Saving memory state to disk - this may take a few minutes...")
                self.ec2_client.stop_instances(
                    InstanceIds=[instance_id],
                    Hibernate=True
                )
            
            print(f"Hibernation initiated for instance {instance_id}")
            print("Note: Instance will enter 'stopped' state when hibernation completes.")
            print("Use 'spotman hibernate resume <instance>' to restore the hibernated state.")
            return True
            
        except ClientError as e:
            print(f"Error hibernating instance {instance_id}: {e}")
            # Check if it's a hibernation-specific error
            if "does not support hibernation" in str(e):
                print("This instance type or configuration doesn't support hibernation.")
                print("Try using a hibernation-compatible instance type (M5, R5, etc.) with encrypted root volume.")
            return False

    def resume_hibernated_instance(self, instance_identifier: str) -> bool:
        """Resume a hibernated EC2 instance by ID or name."""
        # Resolve instance name to ID if needed
        instance_id = self._resolve_instance_identifier(instance_identifier)
        if not instance_id:
            return False
        
        try:
            # First check if the instance is actually stopped
            response = self.ec2_client.describe_instances(InstanceIds=[instance_id])
            instance = response['Reservations'][0]['Instances'][0]
            current_state = instance['State']['Name']
            spot_request_id = instance.get('SpotInstanceRequestId')
            
            if current_state == 'running':
                print(f"Instance {instance_id} is already running!")
                return True
            elif current_state not in ['stopped', 'stopping']:
                print(f"Instance {instance_id} is in '{current_state}' state. Can only resume stopped instances.")
                return False
            
            # Check if hibernation was configured
            hibernation_configured = instance.get('HibernationOptions', {}).get('Configured', False)
            
            # Special handling for hibernated spot instances
            if spot_request_id and hibernation_configured:
                print(f"Resuming hibernated spot instance {instance_id}...")
                print("🔄 Note: Hibernated spot instances require special handling...")
                
                # Check spot request state
                try:
                    spot_response = self.ec2_client.describe_spot_instance_requests(
                        SpotInstanceRequestIds=[spot_request_id]
                    )
                    spot_request = spot_response['SpotInstanceRequests'][0]
                    spot_state = spot_request['State']
                    spot_status = spot_request.get('Status', {}).get('Code', 'unknown')
                    
                    print(f"Spot request {spot_request_id} state: {spot_state}, status: {spot_status}")
                    
                    if spot_status == 'marked-for-stop':
                        print("⚠️  Hibernated spot instance detected!")
                        print("AWS will automatically restart this instance when spot capacity becomes available.")
                        print("You can also try to restart manually, but it may fail if capacity is limited.")
                        print("")
                        
                        # Try to start anyway, but handle the specific spot error gracefully
                        try:
                            print("Attempting manual restart...")
                            self.ec2_client.start_instances(InstanceIds=[instance_id])
                        except ClientError as spot_error:
                            if "IncorrectSpotRequestState" in str(spot_error):
                                print("❌ Manual restart failed: Spot request not in correct state")
                                print("💡 Solutions:")
                                print("   1. Wait for AWS to automatically restart (may take several minutes)")
                                print("   2. Cancel spot request and create new instance")
                                print("   3. Try again in a few minutes when spot capacity increases")
                                print("")
                                print("To cancel and recreate:")
                                print(f"   ./spotman terminate {instance_identifier}")
                                print(f"   ./spotman create --profile spot-hibernation --name {instance_identifier} --class hibernation")
                                return False
                            else:
                                raise spot_error
                    
                except ClientError as spot_check_error:
                    print(f"Warning: Could not check spot request: {spot_check_error}")
                    # Fall through to regular start attempt
                    
            else:
                # Regular hibernated instance (non-spot) or non-hibernated instance
                if hibernation_configured:
                    print(f"Resuming hibernated instance {instance_id}...")
                    print("Note: Hibernated instances may take longer to start as they restore memory state.")
                else:
                    print(f"Resuming stopped instance {instance_id}...")
                
                # Start the instance
                self.ec2_client.start_instances(InstanceIds=[instance_id])
            
            # Wait for instance to be running with extended timeout for hibernated instances
            print("Waiting for instance to start...")
            waiter = self.ec2_client.get_waiter('instance_running')
            
            # Use longer timeout for hibernated instances
            max_attempts = 40 if hibernation_configured else 20  # 40 attempts = ~6.7 minutes
            
            try:
                waiter.wait(
                    InstanceIds=[instance_id],
                    WaiterConfig={
                        'Delay': 10,  # Check every 10 seconds
                        'MaxAttempts': max_attempts
                    }
                )
            except Exception as waiter_error:
                print(f"Timeout waiting for instance to start: {waiter_error}")
                if spot_request_id:
                    print("For spot instances, AWS may restart automatically when capacity becomes available.")
                print("Instance may still be starting. Check AWS console or try again in a few minutes.")
                return False
            
            print(f"Instance {instance_id} resumed successfully!")
            
            if hibernation_configured:
                print("✅ Hibernated state restored - memory contents and running processes preserved!")
            
            return True
            
        except ClientError as e:
            print(f"Error resuming instance {instance_id}: {e}")
            if "IncorrectSpotRequestState" in str(e):
                print("\n💡 This is a known limitation with hibernated spot instances.")
                print("Spot instances in hibernated state may not be manually restartable.")
                print("AWS may restart them automatically when capacity becomes available.")
            return False

    def check_hibernation_status(self, instance_identifier: str) -> None:
        """Check hibernation capability and status of an instance by ID or name."""
        # Resolve instance name to ID if needed
        instance_id = self._resolve_instance_identifier(instance_identifier)
        if not instance_id:
            return
        
        try:
            response = self.ec2_client.describe_instances(InstanceIds=[instance_id])
            instance = response['Reservations'][0]['Instances'][0]
            
            instance_type = instance['InstanceType']
            state = instance['State']['Name']
            hibernation_configured = instance.get('HibernationOptions', {}).get('Configured', False)
            
            # Check if root volume is encrypted (required for hibernation)
            root_volume_encrypted = False
            for bdm in instance.get('BlockDeviceMappings', []):
                if bdm.get('DeviceName') in ['/dev/sda1', '/dev/xvda']:
                    volume_id = bdm['Ebs']['VolumeId']
                    volume_response = self.ec2_client.describe_volumes(VolumeIds=[volume_id])
                    root_volume_encrypted = volume_response['Volumes'][0]['Encrypted']
                    break
            
            print(f"Instance {instance_id} hibernation status:")
            print(f"  Current state: {state}")
            print(f"  Instance type: {instance_type}")
            print(f"  Hibernation configured: {'Yes' if hibernation_configured else 'No'}")
            print(f"  Root volume encrypted: {'Yes' if root_volume_encrypted else 'No'}")
            
            # Check hibernation compatibility
            hibernation_compatible_families = ['m3', 'm4', 'm5', 'm5a', 'm5ad', 'm5d', 'm5dn', 'm5n', 'm5zn',
                                             'r3', 'r4', 'r5', 'r5a', 'r5ad', 'r5b', 'r5d', 'r5dn', 'r5n',
                                             'c3', 'c4', 'c5', 'c5a', 'c5ad', 'c5d', 'c5n']
            instance_family = instance_type.split('.')[0]
            hibernation_compatible = instance_family in hibernation_compatible_families
            print(f"  Hibernation compatible: {'Yes' if hibernation_compatible else 'No'}")
            
            if hibernation_configured and hibernation_compatible and root_volume_encrypted:
                print("  ✅ Instance is ready for hibernation")
            else:
                print("  ❌ Instance cannot be hibernated")
                if not hibernation_configured:
                    print("    - Hibernation not configured during launch")
                if not hibernation_compatible:
                    print(f"    - Instance type {instance_type} doesn't support hibernation")
                if not root_volume_encrypted:
                    print("    - Root volume must be encrypted for hibernation")
            
        except ClientError as e:
            print(f"Error checking hibernation status for {instance_id}: {e}")

    def _merge_profile_config(self, profile: Dict[str, Any], region: str) -> Dict[str, Any]:
        """Merge profile with external region configuration."""
        # Check if this is a legacy profile (has ami_id directly)
        if 'ami_id' in profile:
            print("Using legacy profile format")
            return profile
        
        # Check if we have region configuration loaded
        if not self.regions_config:
            print("Error: No regions configuration available.")
            print("Either use a legacy profile format or create a regions.yaml file.")
            sys.exit(1)
        
        # Start with global defaults from regions.yaml
        config = self.regions_config.get('defaults', {}).copy()
        
        # Add profile-specific settings (these override region defaults)
        config.update(profile)
        
        # Get region-specific configuration
        regions = self.regions_config.get('regions', {})
        if region not in regions:
            print(f"Error: No configuration found for region '{region}' in regions.yaml")
            if regions:
                available_regions = list(regions.keys())
                print(f"Available regions: {available_regions}")
            sys.exit(1)
        
        region_config = regions[region]
        
        # Merge region-specific settings (these have highest priority for region-specific items)
        # AMI ID: use region-specific if available, otherwise use default
        config['ami_id'] = region_config.get('ami_id') or config.get('ami_id')
        # Key name always comes from region config (required per region)
        config['key_name'] = region_config.get('key_name')
        
        # Use region defaults for network settings if not overridden in profile
        if 'security_group_ids' not in profile:
            config['security_group_ids'] = region_config.get('default_security_group_ids', [])
        if 'subnet_id' not in profile:
            default_subnet = region_config.get('default_subnet_id')
            # Only set subnet_id if it's not None and not empty
            if default_subnet and default_subnet.strip():
                config['subnet_id'] = default_subnet
        
        print(f"Using configuration for region: {region}")
        return config

    def _get_spotman_ssh_config_path(self) -> str:
        """Get the path to SpotMan's dedicated SSH config file."""
        config_dir = self._get_config_dir()
        return os.path.join(config_dir, 'ssh_config')

    def _ensure_ssh_include_setup(self) -> None:
        """Ensure the main SSH config includes SpotMan's config file."""
        main_ssh_config = os.path.expanduser('~/.ssh/config')
        spotman_config = self._get_spotman_ssh_config_path()
        include_line = f"Include {spotman_config}"
        
        # Read main SSH config
        try:
            with open(main_ssh_config, 'r') as f:
                content = f.read()
        except FileNotFoundError:
            content = ""
        
        # Check if Include directive already exists
        if include_line not in content:
            # Add Include directive at the top
            new_content = f"{include_line}\n\n{content}"
            
            # Ensure .ssh directory exists
            ssh_dir = os.path.dirname(main_ssh_config)
            os.makedirs(ssh_dir, exist_ok=True)
            
            # Write updated main config
            with open(main_ssh_config, 'w') as f:
                f.write(new_content)
            
            print(f"Added SpotMan SSH config include to {main_ssh_config}")
            print(f"SpotMan SSH entries will be stored in {spotman_config}")

    def _check_ssh_config_exists(self, host_name: str, ssh_config_path: str = None) -> bool:
        """Check if an SSH config entry already exists for the given host name."""
        if not ssh_config_path:
            ssh_config_path = self._get_spotman_ssh_config_path()
        
        try:
            with open(ssh_config_path, 'r') as f:
                content = f.read()
            
            # Check if host entry already exists
            lines = content.split('\n')
            for line in lines:
                if line.strip().startswith(f'Host {host_name}'):
                    return True
            return False
        except FileNotFoundError:
            return False

    def _add_ssh_config_entry(self, instance_id: str, host_name: str, ssh_config_path: str = None) -> bool:
        """Add SSH config entry for a newly created instance."""
        if not ssh_config_path:
            ssh_config_path = self._get_spotman_ssh_config_path()
        
        # Ensure SSH include setup is configured
        self._ensure_ssh_include_setup()
        
        # Get instance details
        try:
            response = self.ec2_client.describe_instances(InstanceIds=[instance_id])
            instance = response['Reservations'][0]['Instances'][0]
            public_ip = instance.get('PublicIpAddress')
            key_name = instance.get('KeyName')
            
            if not public_ip:
                print("Warning: Instance has no public IP address. SSH config entry not created.")
                return False
            
            # Get the SSH key file path from regions configuration
            identity_file = "~/.ssh/your-key.pem"  # Default fallback
            if key_name and self.regions_config and 'ssh_keys' in self.regions_config:
                ssh_keys = self.regions_config['ssh_keys']
                if key_name in ssh_keys:
                    identity_file = ssh_keys[key_name]
                else:
                    print(f"Warning: SSH key '{key_name}' not found in regions configuration. Using default.")
            
            # Create SSH config entry with comment
            ssh_entry = f"""
# SpotMan managed entry for {host_name} ({instance_id})
Host {host_name}
    HostName {public_ip}
    User ubuntu
    IdentityFile {identity_file}
    StrictHostKeyChecking no
"""
            
            # Read existing config or create new
            try:
                with open(ssh_config_path, 'r') as f:
                    content = f.read()
            except FileNotFoundError:
                content = "# SpotMan SSH Configuration\n# This file is automatically managed by SpotMan\n"
            
            # Append new entry
            content = content.rstrip() + ssh_entry + '\n'
            
            # Ensure SpotMan config directory exists
            config_dir = os.path.dirname(ssh_config_path)
            os.makedirs(config_dir, exist_ok=True)
            
            # Write updated SSH config
            with open(ssh_config_path, 'w') as f:
                f.write(content)
            
            print(f"SSH config entry added to {ssh_config_path}")
            print(f"You can now connect with: ssh {host_name}")
            return True
            
        except Exception as e:
            print(f"Error adding SSH config entry: {e}")
            return False

    def create_instance(self, profile_name: str, name: str = None, app_class: str = None) -> str:
        """Create a new EC2 instance based on a YAML profile."""
        profile = self.load_profile(profile_name)
        
        # Get current region
        current_region = self.region
        
        # Merge default and region-specific configuration
        config = self._merge_profile_config(profile, current_region)
        
        # Extract configuration from merged profile
        image_id = config.get('ami_id')
        instance_type = config.get('instance_type', 't3.micro')
        key_name = config.get('key_name')
        security_groups = config.get('security_groups', [])
        security_group_ids = config.get('security_group_ids', [])
        subnet_id = config.get('subnet_id')
        user_data = profile.get('user_data', '')
        os_type = config.get('os_type', 'ubuntu')
        update_os = config.get('update_os', True)
        spot_instance = config.get('spot_instance', False)
        hibernation_enabled = config.get('hibernation_enabled', False)
        root_volume_size = config.get('root_volume_size', 8)
        root_volume_type = config.get('root_volume_type', 'gp3')
        
        # Validate required fields
        if not config.get('ami_id'):
            print(f"Error: No AMI ID specified for region {current_region}")
            print("Either specify ami_id in the region configuration or set a default ami_id.")
            sys.exit(1)
        if not config.get('key_name'):
            print(f"Error: No key pair specified for region {current_region}")
            sys.exit(1)
        
        # Show which AMI is being used
        ami_source = "region-specific" if current_region in self.regions_config.get('regions', {}) and 'ami_id' in self.regions_config['regions'][current_region] else "default"
        print(f"Using {ami_source} AMI: {image_id}")
        
        # Validate hibernation compatibility
        if hibernation_enabled:
            hibernation_compatible_families = ['m3', 'm4', 'm5', 'm5a', 'm5ad', 'm5d', 'm5dn', 'm5n', 'm5zn',
                                             'r3', 'r4', 'r5', 'r5a', 'r5ad', 'r5b', 'r5d', 'r5dn', 'r5n',
                                             'c3', 'c4', 'c5', 'c5a', 'c5ad', 'c5d', 'c5n']
            instance_family = instance_type.split('.')[0]
            if instance_family not in hibernation_compatible_families:
                print(f"Warning: Instance type {instance_type} may not support hibernation.")
                print(f"Hibernation-compatible families: {hibernation_compatible_families}")
        
        # Show configuration summary
        print(f"Instance type: {instance_type}")
        print(f"Spot instance: {'Yes' if spot_instance else 'No'}")
        print(f"Hibernation: {'Enabled' if hibernation_enabled else 'Disabled'}")
        print(f"Root volume: {root_volume_size}GB ({root_volume_type})")
        
        # Prepare tags
        tags = profile.get('tags', {})
        if name:
            tags['Name'] = name
        if app_class:
            tags['ApplicationClass'] = app_class
        if 'ApplicationClass' not in tags and not app_class:
            print("Warning: No application class specified. Use --class or add it to the profile.")
        
        # Check if SSH config entry already exists for this name
        host_name = name if name else None
        if host_name and self._check_ssh_config_exists(host_name):
            print(f"Error: SSH config entry for '{host_name}' already exists.")
            print("Please choose a different instance name or remove the existing SSH config entry.")
            sys.exit(1)
        
        # Add creation timestamp
        tags['CreatedBy'] = 'spotman'
        tags['CreatedAt'] = time.strftime('%Y-%m-%d %H:%M:%S')
        if spot_instance:
            tags['InstanceType'] = 'spot'
        if hibernation_enabled:
            tags['HibernationEnabled'] = 'true'
        
        # Convert tags to AWS format
        tag_specifications = [{
            'ResourceType': 'instance',
            'Tags': [{'Key': k, 'Value': str(v)} for k, v in tags.items()]
        }]
        
        # Configure block device mapping for custom root volume
        block_device_mappings = [{
            'DeviceName': '/dev/sda1',  # Default root device for Ubuntu
            'Ebs': {
                'VolumeSize': root_volume_size,
                'VolumeType': root_volume_type,
                'DeleteOnTermination': True,
                'Encrypted': hibernation_enabled  # Hibernation requires encrypted root volume
            }
        }]
        
        # Prepare base launch parameters
        launch_params = {
            'ImageId': image_id,
            'MinCount': 1,
            'MaxCount': 1,
            'InstanceType': instance_type,
            'TagSpecifications': tag_specifications,
            'BlockDeviceMappings': block_device_mappings
        }
        
        # Add hibernation support
        if hibernation_enabled:
            launch_params['HibernationOptions'] = {'Configured': True}
        
        if key_name:
            launch_params['KeyName'] = key_name
        if security_groups:
            launch_params['SecurityGroups'] = security_groups
        if security_group_ids:
            launch_params['SecurityGroupIds'] = security_group_ids
        if subnet_id and subnet_id.strip():
            launch_params['SubnetId'] = subnet_id
        if user_data:
            # Add OS update commands to user data
            if update_os:
                os_update_script = self._get_os_update_script(os_type)
                user_data = f"{os_update_script}\n{user_data}"
            # Encode user data properly - AWS requires Base64 encoding
            launch_params['UserData'] = base64.b64encode(user_data.encode('utf-8')).decode('utf-8')
        
        try:
            print(f"Creating {'spot ' if spot_instance else ''}instance from profile: {profile_name}")
            
            if spot_instance:
                # Modern approach: Use run_instances with InstanceMarketOptions
                # This supports hibernation and all other features
                launch_params['InstanceMarketOptions'] = {
                    'MarketType': 'spot',
                    'SpotOptions': {
                        'SpotInstanceType': 'persistent'
                    }
                }
                
                if hibernation_enabled:
                    print("Creating hibernation-enabled spot instance using InstanceMarketOptions...")
                else:
                    print("Creating spot instance using InstanceMarketOptions...")
                
                response = self.ec2_client.run_instances(**launch_params)
                instance_id = response['Instances'][0]['InstanceId']
                
                print(f"Spot instance {instance_id} created successfully!")
                
            else:
                # Use regular on-demand instance
                response = self.ec2_client.run_instances(**launch_params)
                instance_id = response['Instances'][0]['InstanceId']
            
            print(f"Instance {instance_id} created successfully!")
            
            if hibernation_enabled:
                print("Note: Hibernation is enabled. Use 'sudo systemctl hibernate' to hibernate the instance.")
            
            print("Waiting for instance to be running...")
            
            waiter = self.ec2_client.get_waiter('instance_running')
            waiter.wait(InstanceIds=[instance_id])
            
            print(f"Instance {instance_id} is now running!")
            
            # Add SSH config entry if instance has a name
            if host_name:
                self._add_ssh_config_entry(instance_id, host_name)
            
            return instance_id
            
        except ClientError as e:
            print(f"Error creating instance: {e}")
            sys.exit(1)

    def _get_os_update_script(self, os_type: str) -> str:
        """Get OS update commands based on OS type."""
        if os_type.lower() in ['ubuntu', 'debian']:
            return """#!/bin/bash
apt-get update
apt-get upgrade -y
"""
        elif os_type.lower() in ['amazon', 'rhel', 'centos']:
            return """#!/bin/bash
yum update -y
"""
        else:
            return """#!/bin/bash
# OS update commands not specified for this OS type
"""

    def list_instances(self, app_class: str = None, state: str = None) -> List[Dict]:
        """List all instances, optionally filtered by application class and state."""
        filters = []
        
        if app_class:
            filters.append({
                'Name': 'tag:ApplicationClass',
                'Values': [app_class]
            })
        
        if state:
            filters.append({
                'Name': 'instance-state-name',
                'Values': [state]
            })
        
        try:
            response = self.ec2_client.describe_instances(Filters=filters)
            instances = []
            
            for reservation in response['Reservations']:
                for instance in reservation['Instances']:
                    # Extract tags
                    tags = {tag['Key']: tag['Value'] for tag in instance.get('Tags', [])}
                    
                    instance_info = {
                        'InstanceId': instance['InstanceId'],
                        'InstanceType': instance['InstanceType'],
                        'State': instance['State']['Name'],
                        'PublicIpAddress': instance.get('PublicIpAddress', 'N/A'),
                        'PrivateIpAddress': instance.get('PrivateIpAddress', 'N/A'),
                        'LaunchTime': instance['LaunchTime'],
                        'Name': tags.get('Name', 'N/A'),
                        'ApplicationClass': tags.get('ApplicationClass', 'N/A'),
                        'Tags': tags
                    }
                    instances.append(instance_info)
            
            return instances
            
        except ClientError as e:
            print(f"Error listing instances: {e}")
            return []

    def stop_instance(self, instance_identifier: str) -> bool:
        """Stop an EC2 instance by ID or name."""
        # Resolve instance name to ID if needed
        instance_id = self._resolve_instance_identifier(instance_identifier)
        if not instance_id:
            return False
        
        try:
            print(f"Stopping instance {instance_id}...")
            self.ec2_client.stop_instances(InstanceIds=[instance_id])
            
            waiter = self.ec2_client.get_waiter('instance_stopped')
            waiter.wait(InstanceIds=[instance_id])
            
            print(f"Instance {instance_id} stopped successfully!")
            return True
            
        except ClientError as e:
            print(f"Error stopping instance {instance_id}: {e}")
            return False

    def _resolve_instance_identifier(self, identifier: str) -> Optional[str]:
        """Resolve instance name or ID to instance ID."""
        # If it looks like an instance ID (starts with i-), return as-is
        if identifier.startswith('i-'):
            return identifier
        
        # Otherwise, treat as instance name and look it up
        try:
            filters = [
                {'Name': 'tag:Name', 'Values': [identifier]},
                {'Name': 'instance-state-name', 'Values': ['running', 'stopped', 'pending', 'stopping']}
            ]
            
            response = self.ec2_client.describe_instances(Filters=filters)
            instances = []
            
            for reservation in response['Reservations']:
                for instance in reservation['Instances']:
                    instances.append(instance)
            
            if not instances:
                print(f"No instance found with name '{identifier}'")
                return None
            elif len(instances) > 1:
                print(f"Multiple instances found with name '{identifier}'. Please use instance ID:")
                for instance in instances:
                    state = instance['State']['Name']
                    print(f"  {instance['InstanceId']} ({state})")
                return None
            else:
                return instances[0]['InstanceId']
                
        except ClientError as e:
            print(f"Error looking up instance '{identifier}': {e}")
            return None

    def terminate_instance(self, instance_identifier: str) -> bool:
        """Terminate an EC2 instance by ID or name."""
        # Resolve instance name to ID if needed
        instance_id = self._resolve_instance_identifier(instance_identifier)
        if not instance_id:
            return False
        
        try:
            # Check if this is a spot instance and get spot request ID
            spot_request_id = None
            try:
                response = self.ec2_client.describe_instances(InstanceIds=[instance_id])
                instance = response['Reservations'][0]['Instances'][0]
                spot_request_id = instance.get('SpotInstanceRequestId')
                
                if spot_request_id:
                    print(f"Instance {instance_id} is a spot instance (request: {spot_request_id})")
            except ClientError as e:
                print(f"Warning: Could not check spot instance status: {e}")
            
            # If this is a spot instance, cancel the spot request first
            if spot_request_id:
                try:
                    print(f"Canceling spot request {spot_request_id}...")
                    self.ec2_client.cancel_spot_instance_requests(
                        SpotInstanceRequestIds=[spot_request_id]
                    )
                    print(f"Spot request {spot_request_id} canceled successfully!")
                    print("Now terminating the instance...")
                    
                except ClientError as e:
                    print(f"Error canceling spot request {spot_request_id}: {e}")
                    print("Proceeding with instance termination...")
            
            # Terminate the instance (for both spot and on-demand instances)
            print(f"Terminating instance {instance_id}...")
            self.ec2_client.terminate_instances(InstanceIds=[instance_id])
            
            waiter = self.ec2_client.get_waiter('instance_terminated')
            waiter.wait(InstanceIds=[instance_id])
            
            print(f"Instance {instance_id} terminated successfully!")
            return True
            
        except ClientError as e:
            print(f"Error terminating instance {instance_id}: {e}")
            return False

    def update_ssh_config(self, instance_id: str = None, app_class: str = None, 
                         ssh_config_path: str = None) -> bool:
        """Update SSH config with instance public IP addresses."""
        if not ssh_config_path:
            ssh_config_path = self._get_spotman_ssh_config_path()
        
        # Ensure SSH include setup is configured
        self._ensure_ssh_include_setup()
        
        # Get instances to update
        if instance_id:
            filters = [{'Name': 'instance-id', 'Values': [instance_id]}]
        elif app_class:
            filters = [{'Name': 'tag:ApplicationClass', 'Values': [app_class]}]
        else:
            filters = []
        
        instances = self.list_instances()
        if filters:
            # Filter instances based on criteria
            if instance_id:
                instances = [i for i in instances if i['InstanceId'] == instance_id]
            elif app_class:
                instances = [i for i in instances if i['ApplicationClass'] == app_class]
        
        if not instances:
            print("No instances found matching the criteria.")
            return False
        
        # Read existing SSH config
        ssh_entries = {}
        try:
            with open(ssh_config_path, 'r') as f:
                content = f.read()
        except FileNotFoundError:
            content = ""
        
        # Update SSH config for each instance
        for instance in instances:
            if instance['State'] != 'running' or instance['PublicIpAddress'] == 'N/A':
                continue

            host_name = instance['Name'] if instance['Name'] != 'N/A' else instance['InstanceId']
            
            # Get the instance's key name for proper SSH key lookup
            identity_file = "~/.ssh/your-key.pem"  # Default fallback
            try:
                response = self.ec2_client.describe_instances(InstanceIds=[instance['InstanceId']])
                instance_details = response['Reservations'][0]['Instances'][0]
                key_name = instance_details.get('KeyName')
                
                if key_name and self.regions_config and 'ssh_keys' in self.regions_config:
                    ssh_keys = self.regions_config['ssh_keys']
                    if key_name in ssh_keys:
                        identity_file = ssh_keys[key_name]
                    else:
                        print(f"Warning: SSH key '{key_name}' not found in regions configuration for {host_name}. Using default.")
            except ClientError as e:
                print(f"Warning: Could not get key name for instance {instance['InstanceId']}: {e}")
            
            # Create SSH config entry
            ssh_entry = f"""
Host {host_name}
    HostName {instance['PublicIpAddress']}
    User ubuntu
    IdentityFile {identity_file}
    StrictHostKeyChecking no
"""
            
            # Remove existing entry for this host if it exists
            lines = content.split('\n')
            new_lines = []
            skip_until_next_host = False
            
            for line in lines:
                if line.strip().startswith(f'Host {host_name}'):
                    skip_until_next_host = True
                    continue
                elif line.strip().startswith('Host ') and skip_until_next_host:
                    skip_until_next_host = False
                    new_lines.append(line)
                elif not skip_until_next_host:
                    new_lines.append(line)
            
            content = '\n'.join(new_lines) + ssh_entry
        
        # Write updated SSH config
        try:
            with open(ssh_config_path, 'w') as f:
                f.write(content.strip() + '\n')
            print(f"SSH config updated: {ssh_config_path}")
            return True
        except Exception as e:
            print(f"Error updating SSH config: {e}")
            return False


def format_instances_table(instances: List[Dict]) -> None:
    """Format and print instances in a table."""
    if not instances:
        print("No instances found.")
        return
    
    # Calculate column widths
    headers = ['ID', 'Name', 'Type', 'State', 'Public IP', 'App Class']
    widths = [len(h) for h in headers]
    
    for instance in instances:
        widths[0] = max(widths[0], len(instance['InstanceId']))
        widths[1] = max(widths[1], len(instance['Name']))
        widths[2] = max(widths[2], len(instance['InstanceType']))
        widths[3] = max(widths[3], len(instance['State']))
        widths[4] = max(widths[4], len(instance['PublicIpAddress']))
        widths[5] = max(widths[5], len(instance['ApplicationClass']))
    
    # Print header
    header_line = ' | '.join(h.ljust(w) for h, w in zip(headers, widths))
    print(header_line)
    print('-' * len(header_line))
    
    # Print instances
    for instance in instances:
        row = [
            instance['InstanceId'].ljust(widths[0]),
            instance['Name'].ljust(widths[1]),
            instance['InstanceType'].ljust(widths[2]),
            instance['State'].ljust(widths[3]),
            instance['PublicIpAddress'].ljust(widths[4]),
            instance['ApplicationClass'].ljust(widths[5])
        ]
        print(' | '.join(row))


def main():
    """Main entry point for SpotMan."""
    parser = argparse.ArgumentParser(
        description='SpotMan - AWS EC2 Instance Manager with Application Class Support',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s create --profile web-server --name web01 --class web
  %(prog)s create --profile spot-hibernation --name spot01 --class spot
  %(prog)s list --class web --state running
  %(prog)s stop i-1234567890abcdef0
  %(prog)s stop web01
  %(prog)s terminate i-1234567890abcdef0
  %(prog)s terminate spot01
  %(prog)s update-ssh --class web
  %(prog)s region show
  %(prog)s region set us-west-2
  %(prog)s region list
  %(prog)s hibernate start i-1234567890abcdef0
  %(prog)s hibernate start spot01
  %(prog)s hibernate resume spot01
  %(prog)s hibernate status spot01
        """
    )
    
    parser.add_argument('--region', help='AWS region')
    parser.add_argument('--aws-profile', help='AWS profile to use')
    
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # Create command
    create_parser = subparsers.add_parser('create', help='Create a new instance')
    create_parser.add_argument('--profile', required=True, 
                              help='Profile name (without .yaml extension)')
    create_parser.add_argument('--name', help='Instance name')
    create_parser.add_argument('--class', help='Application class tag')
    
    # List command
    list_parser = subparsers.add_parser('list', help='List instances')
    list_parser.add_argument('--class', help='Filter by application class')
    list_parser.add_argument('--state', choices=['running', 'stopped', 'terminated', 'pending'],
                            help='Filter by instance state')
    list_parser.add_argument('--json', action='store_true', help='Output in JSON format')
    
    # Stop command
    stop_parser = subparsers.add_parser('stop', help='Stop an instance')
    stop_parser.add_argument('instance_id', help='Instance ID or name to stop')
    
    # Terminate command
    terminate_parser = subparsers.add_parser('terminate', help='Terminate an instance')
    terminate_parser.add_argument('instance_id', help='Instance ID or name to terminate')
    
    # Update SSH config command
    ssh_parser = subparsers.add_parser('update-ssh', help='Update SSH config')
    ssh_parser.add_argument('--instance-id', help='Update config for specific instance')
    ssh_parser.add_argument('--class', help='Update config for all instances in app class')
    ssh_parser.add_argument('--config-path', help='SSH config file path (default: ~/.ssh/config)')
    
    # Region management commands
    region_parser = subparsers.add_parser('region', help='Manage default region')
    region_subparsers = region_parser.add_subparsers(dest='region_command', help='Region commands')
    
    # Show current region
    region_subparsers.add_parser('show', help='Show current default region')
    
    # Set default region
    set_region_parser = region_subparsers.add_parser('set', help='Set default region')
    set_region_parser.add_argument('region_name', help='Region name to set as default')
    
    # List available regions
    region_subparsers.add_parser('list', help='List available regions from configuration')
    
    # Hibernation management commands
    hibernation_parser = subparsers.add_parser('hibernate', help='Manage instance hibernation')
    hibernation_subparsers = hibernation_parser.add_subparsers(dest='hibernation_command', help='Hibernation commands')
    
    # Hibernate instance
    hibernate_parser = hibernation_subparsers.add_parser('start', help='Hibernate an instance')
    hibernate_parser.add_argument('instance_id', help='Instance ID or name to hibernate')
    
    # Resume instance
    resume_parser = hibernation_subparsers.add_parser('resume', help='Resume a hibernated instance')
    resume_parser.add_argument('instance_id', help='Instance ID or name to resume')
    
    # Check hibernation status
    status_parser = hibernation_subparsers.add_parser('status', help='Check hibernation capability of an instance')
    status_parser.add_argument('instance_id', help='Instance ID or name to check')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        sys.exit(1)
    
    # Initialize manager
    manager = AWSInstanceManager(region=args.region, profile=getattr(args, 'aws_profile', None))
    
    # Execute commands
    if args.command == 'create':
        manager.create_instance(args.profile, args.name, getattr(args, 'class'))
    
    elif args.command == 'list':
        instances = manager.list_instances(getattr(args, 'class'), args.state)
        if args.json:
            print(json.dumps(instances, indent=2, default=str))
        else:
            format_instances_table(instances)
    
    elif args.command == 'stop':
        manager.stop_instance(args.instance_id)
    
    elif args.command == 'terminate':
        manager.terminate_instance(args.instance_id)
    
    elif args.command == 'update-ssh':
        manager.update_ssh_config(args.instance_id, getattr(args, 'class'), args.config_path)
    
    elif args.command == 'region':
        if not args.region_command:
            region_parser.print_help()
            sys.exit(1)
        
        if args.region_command == 'show':
            current_region = manager.get_current_region()
            print(f"Current default region: {current_region}")
            
        elif args.region_command == 'set':
            manager.set_default_region(args.region_name)
            
        elif args.region_command == 'list':
            if manager.regions_config and 'regions' in manager.regions_config:
                regions = list(manager.regions_config['regions'].keys())
                print("Available regions from configuration:")
                for region in sorted(regions):
                    marker = " (current)" if region == manager.get_current_region() else ""
                    print(f"  {region}{marker}")
            else:
                print("No regions configuration found. Create regions.yaml file.")
    
    elif args.command == 'hibernate':
        if not args.hibernation_command:
            hibernation_parser.print_help()
            sys.exit(1)
        
        if args.hibernation_command == 'start':
            manager.hibernate_instance(args.instance_id)
            
        elif args.hibernation_command == 'resume':
            manager.resume_hibernated_instance(args.instance_id)
            
        elif args.hibernation_command == 'status':
            manager.check_hibernation_status(args.instance_id)


if __name__ == '__main__':
    main()
